{
    "docs": [
        {
            "location": "/", 
            "text": "GRACC\n\n\nGRid ACcounting Collector\n\n\n(pronounced \"grok\")\n\n\n\n\nGRACC is a collection of components for implementing resource usage accounting.\n\n\nWhy GRACC?\n\n\nGRACC is meant as a replacement of the Gratia accounting system; the engineering focus is on smaller, independent components rather than a monolithic collector architecture.  The hope is that, by breaking the functionality into a series of smaller components, future architectural changes (such as migration to a new database) can be done without rewriting the entire infrastructure.  For example, forwarding information to a separate accounting database becomes much simpler in this infrastructure.\n\n\nRepositories of interest:\n\n\n\n\nGRACC Collector\n.  An agent which runs on an existing Gratia collector that forwards raw usage records to GRACC.\n\n\nGRACC Monitoring Emails\n.  Simple daily emails overview GRACC activity.", 
            "title": "Introduction"
        }, 
        {
            "location": "/#gracc", 
            "text": "GRid ACcounting Collector  (pronounced \"grok\")   GRACC is a collection of components for implementing resource usage accounting.", 
            "title": "GRACC"
        }, 
        {
            "location": "/#why-gracc", 
            "text": "GRACC is meant as a replacement of the Gratia accounting system; the engineering focus is on smaller, independent components rather than a monolithic collector architecture.  The hope is that, by breaking the functionality into a series of smaller components, future architectural changes (such as migration to a new database) can be done without rewriting the entire infrastructure.  For example, forwarding information to a separate accounting database becomes much simpler in this infrastructure.  Repositories of interest:   GRACC Collector .  An agent which runs on an existing Gratia collector that forwards raw usage records to GRACC.  GRACC Monitoring Emails .  Simple daily emails overview GRACC activity.", 
            "title": "Why GRACC?"
        }, 
        {
            "location": "/dev-docs/agent-arch/", 
            "text": "Agent Architecture\n\n\nThe agents that coordinate for GRACC\n\n\n\n\nUnlike its predecessor Gratia, GRACC is split into a number of agents that coordinate through a message queue.  The intent is that this separates the distinct components into separate modules that can evolve at independent rates.  Further, it provides a mechanism for external entities interested in accounting data to integrate into the system.\n\n\nComponents\n\n\nThe three major centralized components of GRACC include:\n\n\n\n\nMessage queue: A \nRabbitMQ\n service for exchanging messages between system components.  Utilized for its publish-subscribe model and its standardized wire format.\n\n\nGRACC\n - a centralized collector endpoint.  This is a HTTP-based service that listens for incoming records from remote probes, buffers them to disk, then sends them to the message queue.\n\n\nGRACE\n - an \nElasticSearch\n-based data storage service.  Consists of an ElasticSearch database instance and several agents used to populate the system.\n\n\n\n\nOther pieces of the accounting infrastructure include the site probes (which produce the records) and planned web views of the accounting data (likely based on Grafana or Kibana).\n\n\nWe also plan on developing \ngracc-replay\n, a command-line tool for initializing replay of data in the system.  This is meant to:\n\n\n\n\nUpload Gratia raw record tarballs from disk to the message queue.\n\n\nRequest raw data to be resent from a given \nGRACE\n instance to a message queue destination (likely a second \nGRACE\n instance).\n\n\nRequest summary data to be recalculated from a given \nGRACE\n instance to a message queue destination.\n\n\n\n\nAgents\n\n\nListener Agent\n\n\nA agent running on \nGRACE\n.  The listener agent listens for one-time data replication requests (for either raw or summary data) on the message queue and launches an appropriate sub-process to send the data to the requested destination.\n\n\nIt listens on the known queue \n/gracc.\ndb\n.requests\n (as defined on \nMessage Queues\n).  \n\n\nSummary Agent\n\n\nThis agent has two responsibilities:\n\n\n\n\nListening to a message queue (\n/grace.\ndb\n.summary\n) for summary records.  It fetchs the records from the queue and uploads them into ElasticSearch.\n\n\n\n\nPeriodically request new summaries be made by the Listener agent.  We envision:\n\n\n\n\n\n\nEvery 15 minutes, we re-summarize the past 2 days of data.\n\n\n\n\nEvery 12 hours, we re-summarize the past 30 days of data.\n\n\n\n\nThis allows late raw records to be included in the summary information.\n\n\nRaw Agent\n\n\nAn agent which listens to one or more message queues (typically, its own queue for replay information and one or more collector queues) for raw records.  Records are read off the queue and uploaded to the database.\n\n\nFuture components\n\n\nComponents that will likely be needed in the future include:\n\n\n\n\nGRACE-B\n: Listens for raw records and serializes them to disk; on a daily basis, compact them into a tarball and upload them to archival storage.\n\n\nGRACE-D\n: A \ndead letter queue\n: a destination for any unparseable or otherwise-rejected records.\n\n\nSome destination for status information.  Every 15 minutes, each component should generate a short status update (analogous to a HTCondor daemon's ClassAd in a \ncondor_collector\n) and serialize it to a database.", 
            "title": "Agent Architecture"
        }, 
        {
            "location": "/dev-docs/agent-arch/#agent-architecture", 
            "text": "The agents that coordinate for GRACC   Unlike its predecessor Gratia, GRACC is split into a number of agents that coordinate through a message queue.  The intent is that this separates the distinct components into separate modules that can evolve at independent rates.  Further, it provides a mechanism for external entities interested in accounting data to integrate into the system.", 
            "title": "Agent Architecture"
        }, 
        {
            "location": "/dev-docs/agent-arch/#components", 
            "text": "The three major centralized components of GRACC include:   Message queue: A  RabbitMQ  service for exchanging messages between system components.  Utilized for its publish-subscribe model and its standardized wire format.  GRACC  - a centralized collector endpoint.  This is a HTTP-based service that listens for incoming records from remote probes, buffers them to disk, then sends them to the message queue.  GRACE  - an  ElasticSearch -based data storage service.  Consists of an ElasticSearch database instance and several agents used to populate the system.   Other pieces of the accounting infrastructure include the site probes (which produce the records) and planned web views of the accounting data (likely based on Grafana or Kibana).  We also plan on developing  gracc-replay , a command-line tool for initializing replay of data in the system.  This is meant to:   Upload Gratia raw record tarballs from disk to the message queue.  Request raw data to be resent from a given  GRACE  instance to a message queue destination (likely a second  GRACE  instance).  Request summary data to be recalculated from a given  GRACE  instance to a message queue destination.", 
            "title": "Components"
        }, 
        {
            "location": "/dev-docs/agent-arch/#agents", 
            "text": "", 
            "title": "Agents"
        }, 
        {
            "location": "/dev-docs/agent-arch/#listener-agent", 
            "text": "A agent running on  GRACE .  The listener agent listens for one-time data replication requests (for either raw or summary data) on the message queue and launches an appropriate sub-process to send the data to the requested destination.  It listens on the known queue  /gracc. db .requests  (as defined on  Message Queues ).", 
            "title": "Listener Agent"
        }, 
        {
            "location": "/dev-docs/agent-arch/#summary-agent", 
            "text": "This agent has two responsibilities:   Listening to a message queue ( /grace. db .summary ) for summary records.  It fetchs the records from the queue and uploads them into ElasticSearch.   Periodically request new summaries be made by the Listener agent.  We envision:    Every 15 minutes, we re-summarize the past 2 days of data.   Every 12 hours, we re-summarize the past 30 days of data.   This allows late raw records to be included in the summary information.", 
            "title": "Summary Agent"
        }, 
        {
            "location": "/dev-docs/agent-arch/#raw-agent", 
            "text": "An agent which listens to one or more message queues (typically, its own queue for replay information and one or more collector queues) for raw records.  Records are read off the queue and uploaded to the database.", 
            "title": "Raw Agent"
        }, 
        {
            "location": "/dev-docs/agent-arch/#future-components", 
            "text": "Components that will likely be needed in the future include:   GRACE-B : Listens for raw records and serializes them to disk; on a daily basis, compact them into a tarball and upload them to archival storage.  GRACE-D : A  dead letter queue : a destination for any unparseable or otherwise-rejected records.  Some destination for status information.  Every 15 minutes, each component should generate a short status update (analogous to a HTCondor daemon's ClassAd in a  condor_collector ) and serialize it to a database.", 
            "title": "Future components"
        }, 
        {
            "location": "/dev-docs/message-queues/", 
            "text": "Message Queues\n\n\nMessage queues used in GRACC\n\n\n\n\nWell known message queues used:\n\n\n\n\n/gracc.\ncollector\n.raw\n - Listens to raw records to insert into the collector.  This is the interface that probes would send raw records.\n\n\n/grace.\ndb\n.summary\n - Listens for summary records to insert into a specific \ndb\n.  This is used to replicate summary records from other collectors or db's.\n\n\n/grace.\ndb\n.raw\n - Raw record queue for a database instance.\n\n\n/grace.\ndb\n.requests\n - The \nAd Agent\n listens to this queue for requests for raw and summary replications.\n\n\n\n\nHere, \ndb\n is the instance name of a given database install while \ncollector\n is the instance name of an existing Gratia collector.\n\n\nThere are currently three defined message schemas in GRACC: raw records, summary records, and replay requests:\n\n\nRaw Records\n\n\nThese are JSON-formatted documents; the key-value pairs are derived from the OGF \nUsageRecord\n format.  For ease of compatibility with the prior Gratia system, we include an \nnjobs\n attribute if a given record represents more than one job.\n\n\nTODO: copy JSON document here.\n\n\n\n\n\n\nNote\n\n\nWe consider these to be \"base\" keys: additional ones may be given (for example, if the record is derived from a HTCondor ClassAd).\n\n\n\n\nSummary Records\n\n\nThe summary record represents a grouping of multiple similar raw records.  In GRACC, we often group jobs run on the same date, by the same user, on the same resource.\n\n\nTODO: copy JSON document here\n\n\n\n\nReplay Requests\n\n\nThe replay request indicates that a remote listener agent attached to an ElasticSearch database should load and re-send some amount of data.\n\n\nKeys\n:\n\n\n\n\ntime_range\n: A Lucene-formatted time range containing the data that should be resent.\n\n\nkind\n: What type of records should be resent (valid values are curently \nraw\n or \nsummary\n).\n\n\ndestination\n: A queue on the same broker where records should be sent.  Should be a string value.\n\n\nfilter\n: A ElasticSearch-formatted query filter (JSON value).  Only records matching this filter should be sent.\n\n\n\n\nExample\n\n\n{\n \ntime_range\n: \nnow-3d\n,\n \nkind\n: \nraw\n,\n \ndestination\n: \n/grace.osg.raw\n,\n \nfilter\n: {\n            \nquery\n: {\n             \nquery_string\n: {\n              \nquery\n: \nvo=cms\n,\n             }\n            }\n           }\n}", 
            "title": "Message Queues"
        }, 
        {
            "location": "/dev-docs/message-queues/#message-queues", 
            "text": "Message queues used in GRACC   Well known message queues used:   /gracc. collector .raw  - Listens to raw records to insert into the collector.  This is the interface that probes would send raw records.  /grace. db .summary  - Listens for summary records to insert into a specific  db .  This is used to replicate summary records from other collectors or db's.  /grace. db .raw  - Raw record queue for a database instance.  /grace. db .requests  - The  Ad Agent  listens to this queue for requests for raw and summary replications.   Here,  db  is the instance name of a given database install while  collector  is the instance name of an existing Gratia collector.  There are currently three defined message schemas in GRACC: raw records, summary records, and replay requests:", 
            "title": "Message Queues"
        }, 
        {
            "location": "/dev-docs/message-queues/#raw-records", 
            "text": "These are JSON-formatted documents; the key-value pairs are derived from the OGF  UsageRecord  format.  For ease of compatibility with the prior Gratia system, we include an  njobs  attribute if a given record represents more than one job.  TODO: copy JSON document here.   Note  We consider these to be \"base\" keys: additional ones may be given (for example, if the record is derived from a HTCondor ClassAd).", 
            "title": "Raw Records"
        }, 
        {
            "location": "/dev-docs/message-queues/#summary-records", 
            "text": "The summary record represents a grouping of multiple similar raw records.  In GRACC, we often group jobs run on the same date, by the same user, on the same resource.  TODO: copy JSON document here", 
            "title": "Summary Records"
        }, 
        {
            "location": "/dev-docs/message-queues/#replay-requests", 
            "text": "The replay request indicates that a remote listener agent attached to an ElasticSearch database should load and re-send some amount of data.  Keys :   time_range : A Lucene-formatted time range containing the data that should be resent.  kind : What type of records should be resent (valid values are curently  raw  or  summary ).  destination : A queue on the same broker where records should be sent.  Should be a string value.  filter : A ElasticSearch-formatted query filter (JSON value).  Only records matching this filter should be sent.   Example  {\n  time_range :  now-3d ,\n  kind :  raw ,\n  destination :  /grace.osg.raw ,\n  filter : {\n             query : {\n              query_string : {\n               query :  vo=cms ,\n             }\n            }\n           }\n}", 
            "title": "Replay Requests"
        }
    ]
}